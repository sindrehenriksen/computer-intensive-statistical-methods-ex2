<<echo=FALSE, cache=FALSE>>=
read_chunk("../code/problem3.R")
@
\section{}
\label{sec:ex3}
In exercise 2 we have run an MCMC-algorithm and generated $M = 70000$ samples. In this exercise we will look at these results and determine the goodness of our MCMC algorithm and potential improvements.
First we define the libraries we used.
%
<<libs3, eval = FALSE, fig.align='center', fig.width=6, fig.height=4, fig.cap="fig caption">>==
@
%
To create the figures we used \texttt{ggplot} from the \textbf{tidyverse} package.
From the samples of $\vect{\eta}$ we can calculate the samples of $\vect{v}$ by the equation $\vect{v} = \vect{\eta} - \vect{u}$. We look at 3 randomly chosen components of $\vect{u}$ and $\vect{v}$ and the samples of $\kappa_u$ and $\kappa_v$.
%
<<dfCreate, eval = FALSE>>==
@
%
%
\paragraph{(a)}
To start out we look at trace plots with a chosen burn in period removed. The size of the burn-in is chosen by looking at the trace plots in figure \ref{fig:trace} and by the results of the Geweke test in 3c. We chose $20000$ to be our burn-in. Which means that we use $50000$ samples as usable samples. 
<<3a, eval = FALSE>>==
@
%
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/trace.pdf}
    \caption{Trace plot of the parameters of interest after removing the burn-in.}
    \label{fig:trace}
\end{figure}

Looking at the trace plots for the three different parameters for $\vect{u}$ and $\vect{v}$ in figure \ref{fig:trace}, we see that the parameters explore much of the domain, and look like a band. This is a good indication of convergence of the MCMC. $\kappa_u$ and $\kappa_v$ seem to explore less of the domain, and they tend to explore more higher values than the mean than smaller values. Also we see the mean of the $\vect{v}$ components is close to zero which is what we should expect for white noise. 
\paragraph{(b)}
Using the same samples we will now look at their autocorrelation. We will do this by using the R-function \texttt{acf}, and then create autocorrelation plots of the different samples.  
%
<<3b, eval = FALSE>>==
@
%
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/acf.pdf}
    \caption{Autocorrelation plots for the parameters of interest after the burn-in is removed.}
    \label{fig:acf}
\end{figure}
%
In figure \ref{fig:acf} we can see that the autocorrelation for $\vect{v}$ is small, but we can see that for the $\vect{u}$ components there is a small autocorrelation for small lags and they look to be independent around lag$\approx20$. On the other hand $\kappa_u$ and $\kappa_v$ we can see a larger degree of autocorrelation. $\kappa_v$ is close to independent around a lag of size $70$ and $\kappa_u$ needs almost a lag of $150$ to be independent. 

\paragraph{(c)}
Next we will test the convergence of the Markov chain using the \texttt{geweke.diag} function from the R-package \textbf{coda}. Geweke's diagnostic is done by comparing the location of the sampled parameter on two different time intervals. Usually one compares the last half of the chain with some smaller part in the start of the chain. We have chosen the first part to be $10\%$ of the start of the chain after the burn-in and the last interval to be $50\%$ of the last part of the chain. Let first interval of a parameter be $\theta_A$ of length $n_A$, with the mean $\bar{\Theta}_A$ and the standard error $s_A$. And the last interval be $\Theta_B$ of length $n_B$, with mean $\bar{\Theta}_B$ and standard error $s_B$. Then the Geweke's statistics is given by Equation \eqref{eq:z-statistics}.

\begin{equation}
    Z_{\Theta} = \frac{\bar{\Theta}_A-\bar{\Theta}_B}{\sqrt{\frac{S_A}{n_A}+\frac{s_B}{n_B}}}
    \label{eq:z-statistics}
\end{equation}

If the samples then are asymptotically independent and drawn from the stationary distribution of the chain, the Geweke's statistic, will be standard normally distributed, $\N(0,1)$, and the p-values are given by
\begin{equation*}
    p\textrm{-value} = P(|Z| \geq |z|).
\end{equation*}

This mean that we can test the convergence of the chain on the p-values of the z-statistics. We can then perform hypothesis tests
\begin{equation}
    \mathrm{H}_0: P(|Z| \geq |z| ) > 0.05
    \enspace \textrm{vs.}\enspace \mathrm{H}_1: P(|Z| \geq |z|) < 0.05,
\end{equation}
with the chosen significance level of $0.05$. We could also chose a interval of $z$ for which the Geweke's statistic needs to be within to have convergence. 
We calculate the Geweke diagnostic with the following code, removing the burn-in from the chain. 
%
<<3c, eval = FALSE>>==
@
%
<<tableGweke, echo = FALSE>>==
@
%
From Table \ref{tab:geweke} returned from the code we see that the hypothesis $\mathrm{H}_0$ is accepted for $\kappa_u$, $\kappa_v$ and the three randomly chosen components of $\vect{u}$ and $\vect{v}$, which indicates that the chain has converged with a burn-in of $20000$. We can also look at the size of the burn-in and at which values the hypothesis doesn't hold. This we have done by plotting the z-statistics for different sizes of burn-in, and since it is normally distributed we can decide which interval the values need to be within for the sequence to have converged. A interval of $Z\in[-1.6,1.6]$ gives a significance level of $0.055$.
%
<<plotgeweke, eval = FALSE>>==
@
%
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/test_burnin.pdf}
    \caption{A comparison of the Geweke's Statistical of our chain with different burn-in. The y-axis is the burn-in size, the x-axis is the z-statistic and the colors of the points is the different parameters. The blue box is the significance level of $p = 0.055$.}
    \label{fig:test_burnin}
\end{figure}

From figure \ref{fig:test_burnin} we can see that the chain has converged with a burn-in of $18000$ according to the Geweke diagnostic. We choose to use a burn-in of $20000$ samples.